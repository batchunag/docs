# Chat

<p className="subtitle">Chat directly with AI to ask questions about your code, generate code, and edit code.</p>

You can **chat** with Cody to ask questions about any part of your codebase or specific code snippets. You can do it from the chat panel of the supported editor extensions (VS Code, JetBrains) or from the web app.

Cody has context of your open file and repository by default, and you can use `@-mention` to add context on specific files, symbols, remote repositories, or other non-code artifacts.

You can learn more about the IDE support for these functionalities in the [feature parity reference](/cody/clients/feature-reference#chat).

## How does chat work?

Cody answers questions by searching your codebase and retrieving context relevant to your questions. Cody uses several methods to search for context like Sourcegraph's native search API and keyword search. Finding and using context allows Cody to make informed responses based on your code rather than being limited to general code knowledge. When Cody retrieves context to answer a question, it will tell you which code files it read to generate its response.

Cody can assist you with various use cases such as:

- Generating an API call: Cody can analyze your API schema to provide context for the code it generates
- Locating a specific component in your codebase: Cody can identify and describe the files where a particular component is defined
- Handling questions that involve multiple files, like understanding data population in a React app: Cody can locate React component definitions, helping you understand how data is passed and where it originates

Let's learn how Cody chat works with different IDE extensions (VS Code, JetBrains) and the Sourcegraph web app.

<Tabs>
<Tab title="VS Code">

  ## Prerequisites

To use Cody's chat in VS Code, you'll need to have the following:

- A Free Sourcegraph.com or a Sourcegraph Enterprise account
- Cody for VS Code editor extension installed and activated

  ## Chat interface

  Cody chat in VS Code is available in a unified interface opened right next to your code. Once connected to Sourcegraph, a new chat input field is opened with a default `@-mention` [context chips](#context-retrieval).

  All your previous and existing chats are stored for later use and can be accessed via the **History** icon from the top menu. You can download them to share or use later in a `.json` file or delete them altogether.

  The chat interface is designed intuitively. Your very first chat input lives at the top of the panel, and the first message in any chat log will stay pinned to the top of the chat. After your first message, the chat input window moves to the bottom of the sidebar.

  Since your first message to Cody anchors the conversation, you can return to the top chat box anytime, edit your prompt, or re-run it using a different LLM model.

  <video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
    <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/chat-interface-0724.mp4" type="video/mp4" />
  </video>

  ## Chat history

  A chat history icon at the top of your chat input window allows you to navigate between chats (and search chats) without opening the Cody sidebar.

  ## LLM selection

  <Callout type="note"> You need to be a Cody Free or Pro user to have multi-model selection capability. Enterprise users with the new [model configuration](/cody/clients/model-configuration) can use the LLM selection dropdown to choose a chat model.</Callout>

For LLM selection for chat:

- Open chat or toggle between editor and chat (Opt+L/Alt+L)
- Click on the model selector (which by default indicates Claude 3.5 Sonnet)
- See the selection of models and click the model you desire. This model will now be the default model going forward on any new chats

For LLM selection for inline edit:

- On any file, select some code and a right-click
- Select Cody->Edit Code (optionally, you can do this with Opt+K/Alt+K)
- Select the default model available (this is Claude 3 Opus)
- See the selection of models and click the model you desire. This model will now be the default model going forward on any new edits


  ## Ask Cody your first question

Let's use Cody chat interface to answer your first question.

- Click the Cody icon from the sidebar in VS Code to open the chat panel
- The chat input field will show pre-added context about the files and repository it reads
- If you want to add or remove context, you can use the `@-mention` syntax
- Select your LLM via the drop-down. By default Cody will use Claude Sonnet 3.5 for chat
- Write your question or instruction to Cody and then press **Enter**.

Cody will take a few seconds to process your question, providing contextual information about the files it reads and generating the answer.

<video width="1920" height="1080" loop playsInline controls style={{ width: '100%', height: 'auto', aspectRatio: '1920 / 1080' }}>
  <source src="https://storage.googleapis.com/sourcegraph-assets/Docs/Media/chat-interface-0724.mp4" type="video/mp4" />
</video>

## Ask Cody to write code

The chat feature can also write code for your questions. For example, in VS Code, ask Cody to "write a function that sorts an array in ascending order".

You are provided with code suggestions in the chat window along with the following options for using the code.

- The **Copy Code** icon to your clipboard and paste the code suggestion into your code editor
- Insert the code suggestion at the current cursor location by the **Insert Code at Cursor** icon
- The **Save Code to New File** icon to save the code suggestion to a new file in your project

During the chat, if Cody needs additional context, it can ask you to provide more information with a follow-up question. If your question is beyond the scope of the context, Cody will ask you to provide an alternate question aligned with the context of your codebase.

## Selecting Context

Cody's chat allows you to add files and symbols as context in your messages.

- Type `@` and then a filename to include a file as context
- Type `@#` and then a symbol name to include the symbol's definition as context. Functions, methods, classes, types, etc., are all symbols

Cody's experimental [OpenCtx](/cody/capabilities/openctx) support adds even more context sources, including Jira, Linear, Google Docs, Notion, and more.
</Tab>
</Tabs>

### Chat vs Commands

There could be scenarios when Cody's chat might not be able to answer your question. Or the answer lacks the context that you need. In these cases, it's recommended to use Cody **commands**. Cody's responses to commands might be better at times than responses to chats since they've been pre-packaged and prompt-engineered.

<Callout type="note"> Commands are only supported in the VS Code and JetBrains extension.</Callout>
